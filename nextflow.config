/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    ferlab/postprocessing Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/

// Global default params, used in configs
params {

    // TODO nf-core: Specify your pipeline's command line flags
    // Input options
    input                      = null
    step                       = 'genotype'
    allow_intermediate_input   = true

    // References
    genome                     = null
    igenomes_base              = 's3://ngi-igenomes/igenomes/'
    igenomes_ignore            = false
    referenceGenome = null
    referenceGenomeFasta = null
    broad = null
    intervalsFile = null
    dbsnpFile = null
    dbsnpFileIndex = null
    vep_cache = null
    vep_cache_version = null
    vep_genome = null
    exomiser_genome  = null
    exomiser_data_dir = null
    exomiser_data_version = null
    exomiser_cadd_version = null
    exomiser_cadd_indel_filename = null
    exomiser_cadd_snv_filename  = null
    exomiser_remm_version = null
    exomiser_remm_filename = null
    exomiser_analysis_wes = "${projectDir}/assets/exomiser/default_exomiser_WES_analysis.yml"
    exomiser_analysis_wgs = "${projectDir}/assets/exomiser/default_exomiser_WGS_analysis.yml"
    exomiser_local_frequency_path = null
    exomiser_local_frequency_index_path = null
    exomiser_start_from_vep = false

    // Execution options
    tools           = ""
    download_cache  = false
    exclude_mnps    = true

    // Output options
	save_genotyped 	= false
	vep_outdir		= null
	outdir_cache	= null
	exomiser_outdir	= null

	//Process-specific parameters
    TSfilterSNP = '99'
    TSfilterINDEL = '99'
    hardFilters = [
        [name: 'QD2', expression: 'QD < 2.0'],
        [name: 'QD1', expression: 'QD < 1.0'],
        [name: 'QUAL30', expression: 'QUAL < 30.0'],
        [name: 'SOR3', expression: 'SOR > 3.0'],
        [name: 'FS60', expression: 'FS > 60.0'],
        [name: 'MQ40', expression: 'MQ < 40.0'],
        [name: 'MQRankSum-12.5', expression: 'MQRankSum < -12.5'],
        [name: 'ReadPosRankSum-8', expression: 'ReadPosRankSum < -8.0']
    ]

    // VQSR parameters
    vqsr_snp_tranches = ["100.0", "99.95", "99.9", "99.8", "99.6", "99.5", "99.4", "99.3", "99.0"]
    vqsr_snp_annotations = ["QD","MQRankSum","ReadPosRankSum","FS","MQ","SOR","DP"]
    vqsr_snp_resources = null  //We cannot define the default value here, as it depends on the broad parameter. It will be initialized in the VQSR workflow.

    allow_old_gatk_data = false
	
	//Resources optionsreferenceGenome
	//defaults expecting to be overwritten
	max_cpus = 16
	max_disk = '200.GB'
	max_time = '12.h'
	max_memory = '120.GB'

    // Boilerplate options
    outdir                       = null
    publish_all                  = false
    publish_dir_mode             = 'copy'
    monochrome_logs              = false
    help                         = false
    version                      = false
    pipelines_testdata_base_path = 'https://raw.githubusercontent.com/nf-core/test-datasets/'

    // Config options
    config_profile_name        = null
    config_profile_description = null
    custom_config_version      = 'master'
    custom_config_base         = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"

    // Schema validation default options
    validationFailUnrecognisedParams = false
    validationLenientMode            = false
    validationSchemaIgnoreParams     = 'genomes,igenomes_base'
    validationShowHiddenParams       = false
    validate_params                  = true


}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load nf-core custom profiles from different Institutions
try {
    includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
    System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}

profiles {
    debug {
        dumpHashes              = true
        process.beforeScript    = 'echo $HOSTNAME'
        cleanup                 = false
        nextflow.enable.configProcessNamesValidation = true
    }
    conda {
        conda.enabled           = true
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        conda.channels          = ['conda-forge', 'bioconda', 'defaults']
        apptainer.enabled       = false
    }
    mamba {
        conda.enabled           = true
        conda.useMamba          = true
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
    }
    docker {
        docker.enabled          = true
        conda.enabled           = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
        docker.runOptions       = '-u $(id -u):$(id -g)'
    }
    arm {
        docker.runOptions       = '-u $(id -u):$(id -g) --platform=linux/amd64'
    }
    singularity {
        singularity.enabled     = true
        singularity.autoMounts  = true
        conda.enabled           = false
        docker.enabled          = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
    }
    podman {
        podman.enabled          = true
        conda.enabled           = false
        docker.enabled          = false
        singularity.enabled     = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
    }
    shifter {
        shifter.enabled         = true
        conda.enabled           = false
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
    }
    charliecloud {
        charliecloud.enabled    = true
        conda.enabled           = false
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        apptainer.enabled       = false
    }
    apptainer {
        apptainer.enabled       = true
        apptainer.autoMounts    = true
        conda.enabled           = false
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
    }
    wave {
        apptainer.ociAutoPull   = true
        singularity.ociAutoPull = true
        wave.enabled            = true
        wave.freeze             = true
        wave.strategy           = 'conda,container'
    }
    gitpod {
        executor.name           = 'local'
        executor.cpus           = 4
        executor.memory         = 8.GB
    }
    test      { includeConfig 'conf/test.config'      }
    test_full { includeConfig 'conf/test_full.config' }
}

// Nextflow plugins
plugins {
    id 'nf-validation@1.1.3' // Validation of pipeline parameters and creation of an input channel from a sample sheet
}

// Load igenomes.config if required
if (!params.igenomes_ignore) {
    includeConfig 'conf/igenomes.config'
} else {
    params.genomes = [:]
}
// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

process {
    disk = 40.GB

	withName: 'variantRecalibratorSNP|variantRecalibratorIndel|applyVQSRIndel|applyVQSRSNP|gatherVCF' {
		container = 'broadinstitute/gatk:4.5.0.0'
	}
    //see conf/base.config for the performance options of defined by nf-core standards
	withName: 'BCFTOOLS_FILTER|BCFTOOLS_NORM|BCFTOOLS_VIEW' {
		errorStrategy = 'retry'
		maxRetries = 1
		cpus	=	{ check_max( 2 		* task.attempt, 'cpus' 		) 	}
		memory	=	{ check_max( 16.GB 	* task.attempt, 'memory'	) 	}
		disk	=	{ check_max( 50.GB 	* task.attempt, 'disk' 		)	}
		time	=	{ check_max( 8.h  	* task.attempt, 'time' 		)	}
	}
	withName: 'COMBINEGVCFS' {
		errorStrategy = 'retry'
		maxRetries = 1
		cpus	=	{ check_max( 4		* task.attempt, 'cpus'		) 	}
		memory	=	{ check_max( 16.GB	* task.attempt, 'memory'	) 	}
		disk	=	{ check_max( 80.GB	* task.attempt, 'disk'		)	}
		time	=	{ check_max( 8.h	* task.attempt, 'time'		)	}
	}
	withName: 'GATK4_GENOTYPEGVCFS' {
		errorStrategy = 'retry'
		maxRetries = 2
		cpus	=	{ check_max( 2		* task.attempt, 'cpus' 		) 	}
		memory	=	{ check_max( 14.GB	* task.attempt, 'memory' 	) 	}
		disk	=	{ check_max( 40.GB	* task.attempt, 'disk' 		)	}
		time	=	{ check_max( 8.h	* task.attempt, 'time' 		)	}
	}
	withName: 'variantRecalibrator.*|apply.*' {
		errorStrategy = 'retry'
		maxRetries = 2
		cpus	=	{ check_max( 2		* task.attempt, 'cpus'		) 	}
		memory	=	{ check_max( 14.GB	* task.attempt, 'memory'	)	}
		disk	=	{ check_max( 30.GB	* task.attempt, 'disk'		)	}
		time	=	{ check_max( 10.h	* task.attempt, 'time'		)	}
	}
	withName: 'splitMultiAllelics' {
		errorStrategy = 'retry'
		maxRetries = 2
		cpus	=	{ check_max( 2		* task.attempt, 'cpus'		) 	}
		memory	=	{ check_max( 14.GB	* task.attempt, 'memory'	)	}
		disk	=	{ check_max( 30.GB	* task.attempt, 'disk'		)	}
		time	=	{ check_max( 10.h	* task.attempt, 'time'		)	}
	}
	withName: 'GATK4_VARIANTFILTRATION' {
		errorStrategy = 'retry'
		maxRetries = 2
		cpus	=	{ check_max( 2		* task.attempt, 'cpus'		) 	}
		memory	=	{ check_max( 14.GB	* task.attempt, 'memory'	)	}
		disk	=	{ check_max( 30.GB	* task.attempt, 'disk'		)	}
		time	=	{ check_max( 10.h	* task.attempt, 'time'		)	}
	}
	withName: 'TABIX_TABIX' {
		errorStrategy = 'retry'
		maxRetries = 2
		cpus	=	{ check_max( 2		* task.attempt, 'cpus'		) 	}
		memory	=	{ check_max( 14.GB	* task.attempt, 'memory'	)	}
		disk	=	{ check_max( 30.GB	* task.attempt, 'disk'		)	}
		time	=	{ check_max( 10.h	* task.attempt, 'time'		)	}
	}
	withName: 'ENSEMBLVEP_DOWNLOAD' {
		errorStrategy = 'retry'
		maxRetries = 2
		cpus	=	{ check_max( 4 		* task.attempt, 'cpus'		)	}
		memory	=	{ check_max( 36.GB	* task.attempt, 'memory'	)	}
		disk	=	{ check_max( 140.GB	* task.attempt, 'disk'		)	}
		time	=	{ check_max( 8.h 	* task.attempt, 'time'		)	}
	}
	withName: 'ENSEMBLVEP_VEP' {
		errorStrategy = 'retry'
		maxRetries = 2
		cpus	=	{ check_max( 4 		* task.attempt, 'cpus'		)	}
		memory	=	{ check_max( 16.GB	* task.attempt, 'memory'	)	}
		disk	=	{ check_max( 80.GB	* task.attempt, 'disk'		)	}
		time	=	{ check_max( 10.h 	* task.attempt, 'time'		)	}
	}
	withName: 'EXOMISER' {
        errorStrategy = 'retry'
		maxRetries = 2
		cpus	=	{ check_max( 6 		* task.attempt, 'cpus'		)	}
		memory	=	{ check_max( 36.GB	* task.attempt, 'memory'	)	}
		disk	=	{ check_max( 150.GB	* task.attempt, 'disk'		)	}
		time	=	{ check_max( 10.h 	* task.attempt, 'time'		)	}
    }
	withName: 'writemeta' {
        container = 'ubuntu:24.10'	
    }
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
	else if (type == 'disk') {
        try {
            if (obj.compareTo(params.max_disk as nextflow.util.MemoryUnit) == 1)
                return params.max_disk as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max disk '${params.max_disk}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

// Disable process selector warnings by default. Use debug profile to enable warnings.
nextflow.enable.configProcessNamesValidation = false

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/pipeline_dag_${trace_timestamp}.html"
}

manifest {
    name            = 'ferlab/postprocessing'
    author          = """Damien Geneste, David Morais, Felix-Antoine Le Sieur, Jeremy Costanza, Lysiane Bouchard"""
    homePage        = 'https://github.com/Ferlab-Ste-Justine/Post-processing-Pipeline'
    description     = """Variant analysis for genome and exome GVCFs"""
    mainScript      = 'main.nf'
    nextflowVersion = '!>=23.10.1'
    version         = '2.8.1'
    doi             = ''
}

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'
